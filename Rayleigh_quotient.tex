
\subsection*{Rayleigh Quotient}
Assume we get a vector $v^{(k)}$ after $k$-step iterations, then we face the problem in solving approximate eigenvalue $x$, i.e. 
$$
x v=Av
$$
Numerically, $Av$ and $v$ are not parallel and this boils down to solving inconsistent linear system. One can apply the conclusion of Least Square to get \textbf{Rayleigh quotient}:
\begin{equation}
    \label{RayleighQ}
    x = \Lambda_{A}(v) := \frac{v^{*}Av}{v^{*}v}
\end{equation}
Also one can get the same result\eqref{RayleighQ} by solving the following optimization problem
\begin{equation}
    \label{optimization1}
    \operatorname{min}_{x} \|Av-x v\|_{2}^{2}
\end{equation}

Geometrically, one find a scalar $x$ such that $Av-xv$ is orthogonal to $v$. Algebraically, eq\eqref{optimization1} (take real case as example) boils down to find the critical point of
$$
f(x)=v^{T}v ^{2}- v^{T}(A^{T}+A)v x+v^{T}A^{T}Av
$$
If $v^{T}A^{T}v$ is real number, then $v^{T}A^{T}v = v^{T}Av$, one can use derivative of $f(x)$ to determine the critical point and the result matches the Least Square. When we consider complex number field, the expansion of $f(x)=\operatorname{min}_{x} \|Av-x v\|_{2}^{2}$ is subtle, saying
$$
f(x)\neq v^{*}v x^{2}- v^{*}(A^{*}+A)v x+v^{*}A^{*}Av
$$
especially $x$ is complex. 

\paragraph{Residue Analysis}
Based on the analysis above, there are orthogonal vectors $v$ and $xv-Av$ and this offers a way to create a self adjoint matrix $B$ such that $v$ is exactly the eigenvector of $B$, which means little difference between $A$ and $B$.

Review example\ref{example04}, one knows that $vr^{*} +r v^{*}$ is a self-adjoint matrix sending $v$ to $r=xv-Av$. We can add this matrix by $A$ to eliminate $Av$, which yields $B=vr^{*} +r v^{*}+A$.