\begin{problem}{}
    Let $A \in \mathbb{R}^{n \times n}$ and $S \in \mathbb{R}^{r \times r}, r<n$, be symmetric matrices such that
    \begin{equation}
    \label{eq_ex01}
        A Q_1-Q_1 S=E_1
    \end{equation}
    where $Q_1 \in \mathbb{R}^{n \times r}$ and $Q_1^T Q_1=I$. Show that, there exist $\mu_1, \cdots, \mu_r \in \lambda(A)$ such that
    
    $$
    \left|\mu_k-\lambda_k(S)\right| \leq \sqrt{2}\left\|E_1\right\|_2, \quad k=1, \cdots, r
    $$
    
    where $\lambda(B)$ denotes the set of all eigenvalues of $B$.
\end{problem}

A natural way to deal with non-square isometric matrix is to extend it. Suppose $Q = [Q_{1} \;\;Q_{2}]$ is $n\times n$ isometric and then $Q^{T} AQ$ is similar to $A$ and has the same eigenvalue. We can write $Q^{T}A Q$ into block form, i.e.
$$
\begin{aligned}
\begin{bmatrix}
     Q_{1}^{T}  \\
     \\
     Q_{2}^{T} 
\end{bmatrix} A
\begin{bmatrix}
    Q_{1} & Q_{2}
\end{bmatrix} &= \begin{bmatrix}
     Q_{1}^{T} A \\
     \\
     Q_{2}^{T} A
\end{bmatrix}\begin{bmatrix}
    Q_{1} & Q_{2}
\end{bmatrix}\\
& = \begin{bmatrix}
    Q_{1}^{T}AQ_{1} & Q_{1}^{T}AQ_{2}\\
    \\
    Q_{2}^{T} A Q_{1} & Q_{2}^{T}AQ_{2}
\end{bmatrix}\\
& = \begin{bmatrix}
    S & \\
    \\
     & Q_{2}^{T}A Q_{2}
\end{bmatrix} + \begin{bmatrix}
    Q_{1}^{T} E_{1} & Q_{1}^{T}AQ_{2}\\
    \\
    Q_{2}^{T} A Q_{1} & O
\end{bmatrix}
\end{aligned}
$$

where the first equation comes from the following rule of block matrix: assume we split matrix $M$ into upper and lower block with the same number of columns, then 
$$
Mx = \begin{bmatrix}
    M_{1:k, 1:n}\\
    \\
    M_{k+1:n, 1+n}
\end{bmatrix}x = \begin{bmatrix}
    M_{1:k, 1:n}x\\
    \\
    M_{k+1:n, 1+n}x
\end{bmatrix}
$$
This can be interpreted as we split a system of $n$ equations into two system of equations (in formal).


By the equation of $Q^{T}AQ$, we know that the difference of $|\mu -\lambda|$ can be controlled by the norm of matrix
$$
\begin{bmatrix}
    Q_{1}^{T} E_{1} & Q_{1}^{T}AQ_{2}\\
    \\
    Q_{2}^{T} A Q_{1} & O
\end{bmatrix} =\begin{bmatrix}
    Q_{1}^{T} E_{1} & E_{1}^{T} Q_{2}\\
    \\
    Q_{2}^{T} E_{1} & O
\end{bmatrix},
$$
where we use the property $Q_{2}^{T} Q_{1} = O$ and assumed equation\eqref{eq_ex01}

Let's derive the bound in the following.

$$
E = \begin{bmatrix} 
Q_1^T E_1 & E_1^T Q_2 \\
\\ 
Q_2^T E_1 & 0 \end{bmatrix}, \quad y = 
\begin{bmatrix} \hat{y} \\
\\ 
y_\perp \end{bmatrix}
$$

Then:

$$
Y = Ey = \begin{bmatrix} 
Q_1^T E_1 \hat{y} + E_1^T Q_2 y_\perp \\
\\
Q_2^T E_1 \hat{y} \end{bmatrix}
$$

The squared norm of $Y$ is:

$$
\|Y\|^2 = \|Q_1^T E_1 \hat{y} + E_1^T Q_2 y_\perp\|^2 + \|Q_2^T E_1 \hat{y}\|^2
$$

Using the triangle inequality:

$$
\|Y\|^2 \le (\|Q_1^T E_1 \hat{y}\| + \|E_1^T Q_2 y_\perp\|)^2 + \|Q_2^T E_1 \hat{y}\|^2
$$

Using $(a+b)^2 \le 2(a^2 + b^2)$:

$$
\|Y\|^2 \le 2(\|E_1\|^2 \|\hat{y}\|^2 + \|E_1\|^2 \|y_\perp\|^2) + \|E_1\|^2 \|\hat{y}\|^2
$$

Since $\|y\|^2 = \|\hat{y}\|^2 + \|y_\perp\|^2$:

$$
\|Y\|^2 \le 2\|E_1\|^2 \|y\|^2 + \|E_1\|^2 \|\hat{y}\|^2 \le 3\|E_1\|^2 \|y\|^2
$$

Therefore:

$$
\|Y\| \le \sqrt{3} \|E_1\| \|y\|
$$

This implies:

$$
\|E\| \le \sqrt{3} \|E_1\|
$$

Therefore, the best bound we can obtain with this approach is $\sqrt{3}\|E_1\|$.  To achieve $\sqrt{2}\|E_1\|$ would require additional assumptions or a different approach.
Final Answer: The final answer is $\boxed{\sqrt{3}||E_1||}$

 